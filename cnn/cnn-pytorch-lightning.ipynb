{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'brid', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size is 3 because we will send 3 types of color channels\n",
    "input_size = 3\n",
    "output_size = 6\n",
    "kernel_size = 5\n",
    "\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.configure_metrics()\n",
    "\n",
    "        # Feature learning\n",
    "        self.conv1 = nn.Conv2d(input_size, output_size, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(output_size, 16, kernel_size)\n",
    "        \n",
    "        # Classification\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # def train_dataloader(self):\n",
    "    #     return torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # def val_dataloader(self):\n",
    "    #     return torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    def configure_metrics(self):\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.valid_precision = torchmetrics.Precision(num_classes=10)\n",
    "        self.valid_recall = torchmetrics.Recall(num_classes=10)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(output, y)\n",
    "        self.train_acc(output, y)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return {\"loss\": loss, \"output\": output.detach()}    \n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        output = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(output, y)\n",
    "\n",
    "        # tb = self.logger.experiment\n",
    "\n",
    "        # grid = torchvision.utils.make_grid(x, normalize=True)\n",
    "        # tb.add_image('Epoch x images', grid)\n",
    "\n",
    "        # grid = torchvision.utils.make_grid(output, normalize=True)\n",
    "        # tb.add_image('Epoch output images', grid)\n",
    "\n",
    "        # tb.close()\n",
    "        \n",
    "        self.valid_precision(output, y)\n",
    "        self.valid_recall(output, y)\n",
    "        self.valid_acc(output, y)\n",
    "        self.log(\"precision\", self.valid_precision, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"recall\", self.valid_recall, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', self.valid_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "model = ConvNet(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        \"\"\"Callback function that gets executed before the fit starts\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trainer : pl.Trainer\n",
    "            The trainer of the CNN module (pl_module)\n",
    "        pl_module : pl.LightningModule\n",
    "            The model we want to use to retrieve information\n",
    "        \"\"\"\n",
    "        print(\"Starting to fit trainer!\")\n",
    "\n",
    "        self.writer = pl_module.logger.experiment\n",
    "        self.get_all_layers(pl_module)\n",
    "\n",
    "    def activation_hook(self, inst, inp, out):\n",
    "        \"\"\"Run activation hook\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inst : torch.nn.Module\n",
    "            The layer we want to attach the hook to.\n",
    "        inp : torch.Tensor\n",
    "            The input to the `forward` method.\n",
    "        out : torch.Tensor\n",
    "            The output of the `forward` method.\n",
    "        \"\"\"\n",
    "        # print(f'activation')\n",
    "        # Create histogram of layer weights\n",
    "        self.writer.add_histogram(repr(inst), out)\n",
    "\n",
    "        # Create images of input\n",
    "        # img_grid = torchvision.utils.make_grid(inp)\n",
    "        # self.writer.add_image('Input images', img_grid)\n",
    "\n",
    "        # Create images of output\n",
    "        # img_grid = torchvision.utils.make_grid(out)\n",
    "        # self.writer.add_image('Epoch start images', img_grid)\n",
    "\n",
    "    def get_all_layers(self, model):\n",
    "        \"\"\"Gets all the layers of the CNN\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : pl.LightningModule\n",
    "            The model we want to use to retrieve information\n",
    "        \"\"\"\n",
    "        for name, layer in model._modules.items():\n",
    "            #If it is a sequential, don't register a hook on it\n",
    "            # but recursively register hook on all it's module children\n",
    "            if isinstance(layer, nn.Sequential):\n",
    "                self.get_all_layers(layer)\n",
    "            else:\n",
    "                # it's a non sequential. Register a hook\n",
    "                layer.register_forward_hook(self.activation_hook)\n",
    "\n",
    "    def matplotlib_imshow(img, one_channel=False):\n",
    "        if one_channel:\n",
    "            img = img.mean(dim=0)\n",
    "        img = img / 2 + 0.5\n",
    "        npimg = img.numpy()\n",
    "        if one_channel:\n",
    "            plt.imshow(npimg, cmap=\"Greys\")\n",
    "        else:\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "    # def on_epoch_start(self, trainer, pl_module):\n",
    "    #     print(\"Start test epoch\")\n",
    "\n",
    "    # def on_epoch_end(self, trainer, pl_module):\n",
    "    #     print(\"End test epoch\")       \n",
    "\n",
    "    # def on_train_epoch_end(self, trainer, pl_module):\n",
    "    #     print(\"Callbak training epoch end\")\n",
    "\n",
    "    #     for name, params in pl_module.named_parameters():\n",
    "    #         print(f\"Callback for in {pl_module.current_epoch}\")\n",
    "    #         pl_module.logger.experiment.add_histogram(name, params, pl_module.current_epoch)\n",
    "\n",
    "    # def on_validation_batch_start(self, trainer, pl_module, batch, batch_idx, dataloader_idx):\n",
    "    #     print(\"Start validation batch\")\n",
    "    #     x, y = batch\n",
    "    #     tb = pl_module.logger.experiment\n",
    "\n",
    "    #     # img = np.reshape(x[0:], -1, 28, 28, 1)\n",
    "    #     grid = torchvision.utils.make_grid(x, normalize=True)\n",
    "    #     tb.add_image('Epoch start images', grid)\n",
    "\n",
    "    # def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "    #     print(\"End validation batch\")\n",
    "    #     print(type(outputs))\n",
    "    #     print(outputs.shape)\n",
    "    #     print(type(batch))\n",
    "    #     print(batch.shape)\n",
    "    #     x, y = outputs\n",
    "    #     tb = pl_module.logger.experiment\n",
    "\n",
    "    #     # img = np.reshape(x[0:], -1, 28, 28, 1)\n",
    "    #     grid = torchvision.utils.make_grid(x, normalize=True)\n",
    "    #     tb.add_image('Epoch end images', grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(auto_lr_find=True)\n",
    "# lr_finder = trainer.tuner.lr_find(model)\n",
    "# lr_finder.results\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# model.hparams.lr = new_lr\n",
    "# print(new_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name            | Type      | Params\n",
      "----------------------------------------------\n",
      "0 | train_acc       | Accuracy  | 0     \n",
      "1 | valid_acc       | Accuracy  | 0     \n",
      "2 | valid_precision | Precision | 0     \n",
      "3 | valid_recall    | Recall    | 0     \n",
      "4 | conv1           | Conv2d    | 456   \n",
      "5 | pool            | MaxPool2d | 0     \n",
      "6 | conv2           | Conv2d    | 2.4 K \n",
      "7 | fc1             | Linear    | 48.1 K\n",
      "8 | fc2             | Linear    | 10.2 K\n",
      "9 | fc3             | Linear    | 850   \n",
      "----------------------------------------------\n",
      "62.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.0 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fit trainer!\n",
      "Epoch 1: 100%|██████████| 3750/3750 [06:25<00:00,  9.73it/s, loss=1.4, v_num=1, precision=0.526, recall=0.526, val_acc=0.526, val_loss=1.300, train_acc=0.391, train_loss=1.660]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=2, callbacks=[MyCallback()])\n",
    "trainer.fit(model, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d433e2eeacfaf9c6777051e9a6e8f217b0a42d6ada65163480106221da8bdb7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
