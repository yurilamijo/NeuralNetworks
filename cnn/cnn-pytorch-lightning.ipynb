{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./CIFAR10/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'brid', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input size is 3 because we will send 3 types of color channels\n",
    "input_size = 3\n",
    "output_size = 6\n",
    "kernel_size = 5\n",
    "\n",
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.configure_metrics()\n",
    "        # self.loss_func = nn.CrossEntropyLoss()\n",
    "        # Feature learning\n",
    "        self.conv1 = nn.Conv2d(input_size, output_size, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(output_size, 16, kernel_size)\n",
    "        # Classification\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.reshape(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    def configure_metrics(self):\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.valid_precision = torchmetrics.Precision(num_classes=10)\n",
    "        self.valid_recall = torchmetrics.Recall(num_classes=10)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(output, y)\n",
    "        # self.loss_func(output, y)\n",
    "        self.train_acc(output, y)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        output = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(output, y)\n",
    "        self.valid_precision(output, y)\n",
    "        self.valid_recall(output, y)\n",
    "        self.valid_acc(output, y)\n",
    "        self.log(\"precision\", self.valid_precision, on_step=False, on_epoch=True)\n",
    "        self.log(\"recall\", self.valid_recall, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc', self.valid_acc, on_step=False, on_epoch=True)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "    \n",
    "    # def on_validation_batch_start(self, batch, batch_idx, dataloader_idx):\n",
    "    #     x, y = batch\n",
    "    #     tb = self.logger.experiment\n",
    "\n",
    "    #     grid = torchvision.utils.make_grid(x)\n",
    "    #     tb.add_image('Epoch start images', grid)\n",
    "\n",
    "    # def on_validation_batch_end(self, outputs, batch, batch_idx, dataloader_idx):\n",
    "    #     x, y = batch\n",
    "    #     tb = self.logger.experiment\n",
    "\n",
    "    #     grid = torchvision.utils.make_grid(x)\n",
    "    #     tb.add_image('Epoch end images', grid)\n",
    "\n",
    "\n",
    "model = ConvNet(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def on_init_start(self, trainer):\n",
    "        print(\"Starting to init trainer!\")\n",
    "\n",
    "    def on_validation_epoch_start(self, trainer, pl_module):\n",
    "        print(\"validation start\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        print(\"validation ends\")\n",
    "\n",
    "    def on_validation_batch_start(self, trainer, pl_module, batch, batch_idx, dataloader_idx):\n",
    "        x, y = batch\n",
    "        tb = pl_module.logger.experiment\n",
    "\n",
    "        # img = np.reshape(x[0:], -1, 28, 28, 1)\n",
    "        grid = torchvision.utils.make_grid(x, normalize=True)\n",
    "        tb.add_image('Epoch start images', grid)\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "        print(type(outputs))\n",
    "        print(outputs.shape)\n",
    "        print(type(batch))\n",
    "        print(batch.shape)\n",
    "        # x, y = outputs\n",
    "        # tb = pl_module.logger.experiment\n",
    "\n",
    "        # # img = np.reshape(x[0:], -1, 28, 28, 1)\n",
    "        # grid = torchvision.utils.make_grid(x, normalize=True)\n",
    "        # tb.add_image('Epoch end images', grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(auto_lr_find=True)\n",
    "# lr_finder = trainer.tuner.lr_find(model)\n",
    "# lr_finder.results\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()\n",
    "# new_lr = lr_finder.suggestion()\n",
    "# model.hparams.lr = new_lr\n",
    "# print(new_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=2, callbacks=[MyCallback()])\n",
    "trainer.fit(model, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d433e2eeacfaf9c6777051e9a6e8f217b0a42d6ada65163480106221da8bdb7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
